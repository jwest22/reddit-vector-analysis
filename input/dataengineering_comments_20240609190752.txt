{"body": "Nah. What we need is for this sub to limit posts like this to one or two days a week, really. Ideally none at all but is what it is.", "author": "OdinsPants", "created_utc": "2024-06-09 19:05:31", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7us1i7/"}
{"body": "Need to get your nose checked", "author": "theoriginalmantooth", "created_utc": "2024-06-09 19:03:23", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7uro8c/"}
{"body": "Interesting. Why did you choose Snowflake over redoing in Redshift (if I understood that correctly)?", "author": "theoriginalmantooth", "created_utc": "2024-06-09 19:00:36", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ur78d/"}
{"body": "If you have an API ingestion pattern, it can do pulling of data and storing on cloud storage,  process in data lake...as long as you don't have hundreds of millions of data it should be your no\u00b01 choice due to zero costs", "author": "UpstairsEye4793", "created_utc": "2024-06-09 18:58:35", "permalink": "/r/dataengineering/comments/1dbz2y4/duckdb_how_are_you_using_it_in_production/l7uquv0/"}
{"body": "We use it for lightweight storage for storing CDC info for connector code. It's great for that.", "author": "FivePoopMacaroni", "created_utc": "2024-06-09 18:52:34", "permalink": "/r/dataengineering/comments/1dbz2y4/duckdb_how_are_you_using_it_in_production/l7uptkg/"}
{"body": "\"We have a contract to migrate data for another company\" - Has your company already committed to timelines / costs / etc.? If your company has already made promises it is obviously not going to be able to keep, you are being set up as the fall guy...", "author": "mammothfossil", "created_utc": "2024-06-09 18:51:21", "permalink": "/r/dataengineering/comments/1dbe3j2/favorite_resources_related_to_project_management/l7uplwn/"}
{"body": "In what kind of situation is it significantly better than polars?", "author": "Zamyatin_Y", "created_utc": "2024-06-09 18:51:12", "permalink": "/r/dataengineering/comments/1dbz2y4/duckdb_how_are_you_using_it_in_production/l7upkyb/"}
{"body": "From startup import unicorn\nPrint(\u201cprofitz!\u201d)", "author": "horus-heresy", "created_utc": "2024-06-09 18:45:31", "permalink": "/r/dataengineering/comments/1dboo9l/2010_2017_ml_pip_install_scikitlearn_2017_2023_ml/l7uol4f/"}
{"body": "How about you unclench yourself.\n\nMajority of people roast Redshift and I\u2019m trying to understand the perspective of actual Redshift users.", "author": "theoriginalmantooth", "created_utc": "2024-06-09 18:41:15", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7unubj/"}
{"body": "Dagster's integration libraries have a ton of low hanging fruit for contributors. Their gcp integrations are pretty minimal. Lots of other integrations that could use some help. You could contribute to prefect or duckdb, no better way to become an expert of a tool you're using than to open up the hood and tinker. All these projects have basically endless issues that need help.", "author": "britishbanana", "created_utc": "2024-06-09 18:41:04", "permalink": "/r/dataengineering/comments/1dbe8p1/i_would_like_collaborate_on_data_projects/l7unt5o/"}
{"body": "Yeah, I wouldn't be surprised if their revenue was closer to ~5 million, i.e. 1000-2000x range", "author": "AnimaLepton", "created_utc": "2024-06-09 18:33:38", "permalink": "/r/dataengineering/comments/1d8118g/databricks_acquires_tabular/l7umipd/"}
{"body": "Amazing \ud83d\ude4c. Thank you so much for the efforts. You just made my day. I got the book I was looking for.\n\nSorry for deviating from your question, I guess you did a great job in going depth and understanding the concepts well. The 90-100 is still very good according to me. \ud83d\ude4c", "author": "Delicious_Attempt_99", "created_utc": "2024-06-09 18:30:11", "permalink": "/r/dataengineering/comments/1dbax05/how_long_did_it_take_you_to_read_database_system/l7ulxjg/"}
{"body": "Because most don\u2019t go pass the how to guide. And queries are written as they run by magical data spitting dragon.", "author": "Empty_Geologist9645", "created_utc": "2024-06-09 18:26:32", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ulasp/"}
{"body": "Damn I thought it was just megacorp microsoft shops that had this stuff happen", "author": "speedisntfree", "created_utc": "2024-06-09 18:20:48", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ukbm3/"}
{"body": "You do not clarify anything at all. What\u2019s your issue. Because the only thing you look for is validation of some bias that\u2019s based on others opinions.", "author": "Empty_Geologist9645", "created_utc": "2024-06-09 18:20:34", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7uka79/"}
{"body": "It's used in production, but I see it more as a data processing tool rather than a \"database\" (i.e. \"for storing/serving data\").\nIt's an impressive replacement for pandas/polars, especially when memory is an issue.", "author": "stefanondisponibile", "created_utc": "2024-06-09 18:06:53", "permalink": "/r/dataengineering/comments/1dbz2y4/duckdb_how_are_you_using_it_in_production/l7uhxy8/"}
{"body": "Personally I have no qualms with Redshift, I understand there are pros/cons to it but ultimately depends on the use case. I feel the overall sentiment towards Redshift is negative in the DE community, hence my post is trying to find out what companies are doing with Redshift, and if they are planning to jump ship, or stay onboard, reasons for their decisions, etc. Hope that clarifies", "author": "theoriginalmantooth", "created_utc": "2024-06-09 17:56:59", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ug99x/"}
{"body": "The majority of the difference (in a properly run shop, which many are not) should be in stakeholder interactions.\n\nThe senior/staff/etc. is the person you want sitting in on meetings with the business function owners, asking questions to understand what outcomes they want to accomplish, and conceptualizing the most appropriate design based on that.\n\nYou don't have to be super chatty or the one running the meeting. The best Staff I've ever worked with was super quiet by nature. They'd listen intently and ask a clarifying question or two; but when you'd ask them whether they had their head wrapped around the problem, it'd be, \"I'm following them, I'll shoot over what I'm thinking for an approach tomorrow.\"\n\nAll goes to say, the best thing I can recommend for an intermediate is to ask to sit in these meetings - even if you're just watching silently.", "author": "creepystepdad72", "created_utc": "2024-06-09 17:53:15", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7ufm8j/"}
{"body": "The problem with Redshift is the AWS marketing department. Some claims they make in the docs are very close to what one could call lies. So the plan is figuring out how it really works possibly always making a POC beforehand and see if it fits your use case, costs etc. I think redshift is still great for what it's made for: data warehousing.", "author": "stefanondisponibile", "created_utc": "2024-06-09 17:51:41", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ufci7/"}
{"body": "Hey! I have a very similar problem I am trying to solve.  Would you mind giving me an update on what you did?\n\nOne thing I am struggling with is that data may be larger than what Excel can handle, so it going straight to a pivot table and consolidating processing on a remote server.  An OLAP connection to a pivot table would be ideal, but SSAS would be too pricy for what we're looking to do.", "author": "agk23", "created_utc": "2024-06-09 17:51:19", "permalink": "/r/dataengineering/comments/1ax3j11/duckdb_into_excel_pivot_table/l7ufa8d/"}
{"body": "I've never heard of anyone with real scale &amp; velocity is using it in prod", "author": "jaredrileysmith", "created_utc": "2024-06-09 17:49:20", "permalink": "/r/dataengineering/comments/1dbz2y4/duckdb_how_are_you_using_it_in_production/l7uexnz/"}
{"body": "Absolutely. \n\nThe book outside of a few chapters dedicated to SQL, is very theory heavy and puts a lot of emphasis on how the database system ( Relational and NoSQL ) and their auxiliary parts (storage devices / physical level storage structures / RAID arrays ...etc...etc ) work at both a lower and higher level of abstraction, it explains a lot of how certain algorithms and parts function, their benefits and drawbacks, but never actually provides any code outside of pseudo code and the occasional SQL query.\n\nFor example regarding your question of\n\n&gt; what happens when sql query is submitted\n\nThe book explain in Part V how you would store the dataset, both at the physical level ( as in the bits and bytes and also the medium of storage [SSDs/HDDs/Main Memory/Cache etc..]  ) and at a logical level ( as in the type of formatting and data structure to enable efficient processing ), It will also explain how the data is transferred from persistent storage to your main memory ( the costs, but also the physical events ), and what the system does to try and minimize costs ( smart buffer alocation, indexes etc.. ). \n\nIn part VI, it answers the question at the query level, about how the system *tries* to estimate the cost of the query and what kind of algorithms and operations are done at a lower level ( and their drawbacks/best use case scenario ) a lot of relational algebra here too. It then explains how query optimization tries to find the best plan, the way it orders operations/joins based on database stats, the heuristics associated with it and so on. \n\nIn part VII it also answers this question from another level, explaining how after the plan is created, the steps the system will take to fit the transaction into its schedule and try to provide as much concurrency as possible while also respecting the isolation level imposed to it by the user/system. \n\nOf course each system has it's own implementation and you will soon realize how behind/basic some of them can be, but the postgres docs for example provide ample explaining about the internals and how they work, which is generally either very close to the theory or an exact implementation of it. And for me it was rather simple to grasp the ideas after reading the book.\n\nThere is a lot I can say and I would but I've already spent like 20 minutes writing this answer, so in short, it's a wonderful book.", "author": "xyzb206", "created_utc": "2024-06-09 17:47:47", "permalink": "/r/dataengineering/comments/1dbax05/how_long_did_it_take_you_to_read_database_system/l7uenre/"}
{"body": "More autonomy but also more politics. The hardest part is to be a good manager by delegating tasks and then being the one who assures that it fits all together nicely. Constantly fighting against the urge of doing everything myself.", "author": "AndyMacht58", "created_utc": "2024-06-09 17:33:54", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7uc8vl/"}
{"body": "The flaw in your assumption is that the preferences in Reddit are reflected in the general populace.\n\nBased on how their businesses work, for a lot of companies, Redshift is a correct choice (I mean, sure there's personal preference on which OLAP database you like, but that's what it is - personal preference).\n\nThe whole data lake, parquet files, medallion system, whatever whatever that seems to be popular here is a necessity for some applications... But if you're not dealing with a mess of freeform data, in different formats, from all kinds of sources, at a reasonable scale - I'd argue you're being fancy for the sake of it.\n\nA whole lot of organizations out there can simply plug an iPaaS into their transactional sources, route that over to Redshift, do some smart transformations, and call it a wrap.\n\nAt my current company, the business model is suited to a very structured, relational data model. That is, records are super standardized where there's no variation in the fields that the customers see/need - it's just how the industry works. It's also a young company (not in the age of folks, but in we've only been around for a few years) so the business technology systems are all modern SaaS that can bumped out to an OLAP via an iPaaS without writing a line of code.\n\nWhere the personal preference comes in is I don't love the \"hybrid\" object model BigQuery uses (and we don't really need the flexibility of the NoSQL-esque embedding), and we don't need any of the fancy features of Snowflake for the additional cost. Thus, old reliable Redshift makes the most sense.\n\nI'd argue this design decision gives us the largest corpus of potential hires, because it's pretty much, \"Knows Postgres-flavored SQL\".", "author": "creepystepdad72", "created_utc": "2024-06-09 17:24:56", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7uap4d/"}
{"body": "There is a lot more mentorship. Running interviews. Hosting lunch-and-learns. Reviewing architecture. Researching industry trends and tools. Building morale. Working with the business, not just other engineers. It\u2019s less about their own production and more about the team\u2019s production and reputation.\n\nI view the difference between DE, a Senior DE, and a Staff/Lead DE to be their progression on the continuum of responsibility for their own productivity to responsibility for the team\u2019s. They now serve as an accelerator, like a boost of nitro. When a DE thinks they\u2019re ready for a promotion and their pitch is only about their own work, they might be ready for \u201cSenior\u201d. But when their co-workers are advocating for their promotion, then I know they are ready for a \u201cStaff\u201d title.", "author": "_mattmc3_", "created_utc": "2024-06-09 17:15:33", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7u94bg/"}
{"body": "Getting off redshift and getting on to databricks", "author": "Doyale_royale", "created_utc": "2024-06-09 17:12:10", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7u8jzx/"}
{"body": "I've never used Presto directly, though I've used AWS Athena quite a bit - which is an Amazon re-badged version of Presto and its successor Trino.\n\nAnd Athena is absolutely not a hundred times faster than Redshift:\n\n   * it's optimizer is so dumb that it performs joins based on the order that the tables appear in your query - not based on statistics and a modern cost-based optimizer. \n   * at scale you'll spend a ton of time optimizing performance by working on: file formats, file sizes, partitioning, partition catalogs &amp; projection, provisioned vs on-demand compute, caching results, tweaking queries, etc, etc, etc.\n   * and one of the scaling strategies is to migrate to Redshift Spectrum.\n\nNow, you generally don't need to do that if you've got something tiny with just maybe a million rows.  But otherwise, there's a lot of tweaking to be done.\n\nWhich, BTW, doesn't mean it's not worthwhile: since you can deliver a big data reporting solution and data warehouse at a fraction of the price of say Snowflake or BigQuery, and have better low-latency results, and easily migrate to other solutions at some point in time down the road.", "author": "kenfar", "created_utc": "2024-06-09 17:07:12", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7u7pdl/"}
{"body": "You said you wanted to measure over/under usage and trends. Time series are perfect for that, but you cannot pre-compute everything, because you don't know in advance what you will need. When you look at numbers and find anomalies, you may need to make queries with rolling averages, compute regressions and so on.  \n  \nTS database are usually very good at ingesting data, so you will not have any issues with that, even if you make snapshots super frequently. You can combine your metadata and stats into one single payload and table and probably get query responses subsecond with a reasonable setup.  \n  \nIf you are a SQL guy, make sure to chose one TSDB that speaks your language :-)  \n(I can point you to suitable ressource if you DM me).", "author": "NoPlansForNigel", "created_utc": "2024-06-09 16:59:31", "permalink": "/r/dataengineering/comments/1d92cm0/discussion_i_built_a_tool_for_analyzing_sql/l7u6e85/"}
{"body": "You're welcome!", "author": "tinycockatoo", "created_utc": "2024-06-09 16:57:37", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7u62dj/"}
{"body": "Lmao, I dropped out of a Physics degree and I also feel like nothing is difficult anymore", "author": "tinycockatoo", "created_utc": "2024-06-09 16:57:24", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7u613j/"}
{"body": "Oh brother don\u2019t look at redshift spectrum then\u2026", "author": "dilbertdad", "created_utc": "2024-06-09 16:50:41", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7u4vtu/"}
{"body": "Will depend on your exact use case and technical experience but EMRS is cheaper and the resourcing is more configurable, whereas Glue has limited fixed instance sizes.\n\nThe EMR images are generally more up to date and it\u2019s relatively easy to build your own images.", "author": "LoveTrucking", "created_utc": "2024-06-09 16:44:29", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7u3tsq/"}
{"body": "Interesting book. Checked the table of contents. Do you recommend this book for someone who wants to understand the internals of database? Like what happens when sql query is submitted, what happens when a database is created etc?", "author": "Delicious_Attempt_99", "created_utc": "2024-06-09 16:28:20", "permalink": "/r/dataengineering/comments/1dbax05/how_long_did_it_take_you_to_read_database_system/l7u13wp/"}
{"body": "This smells like an intro to another bullshit marketing post", "author": "OdinsPants", "created_utc": "2024-06-09 16:28:05", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7u12fl/"}
{"body": "Making Redshift work right is very challenging, you need real engineers, but if done right, it's the cheapest petabyte scale warehouse.\n\nSnowflake solves a lot of the tinkering needed with Redshift, if you don't have a truckload of data (but still enough that requires a distributed DWH), it's a better choice for sure.", "author": "Mol2h", "created_utc": "2024-06-09 16:16:34", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tz5d2/"}
{"body": "Agree. But I do feel like having to deal with the constraints of Redshift has made me a better engineer in general. I\u2019ve found that every solution claiming to \u201cdo it all for you\u201d does like 70% of it well and you still have to tweak and optimize 30%. The patterns you learn for optimizing often transfer well to other data technologies. But if your solution is always to throw storage/compute/tooling/money at the problems to make them go away then you don\u2019t learn those patterns. So go into any tool assuming you need to learn the gritty details and squeeze all the efficiency out of it.\n\nNot saying I\u2019d choose Redshift when starting from scratch. But knowing the patterns behind Redshift clusters, columnar storage, sortkey and distkey choices, materialization strategies\u2026it gave me a better mental model, and learning it was worthwhile regardless.", "author": "MindlessTime", "created_utc": "2024-06-09 16:16:25", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tz4e6/"}
{"body": "What is wrong working with Redshift?", "author": "aliavni", "created_utc": "2024-06-09 16:08:58", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7txuy1/"}
{"body": "Following", "author": "Delicious_Attempt_99", "created_utc": "2024-06-09 16:03:02", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7twvl3/"}
{"body": "More freedom, more interaction with stakeholders.", "author": "carlsbadcrush", "created_utc": "2024-06-09 16:02:30", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7twsa7/"}
{"body": "I've been working in this platform for 2 years, my team is responsible for bringing customer's raw data to this and transform.\n\n I would say it's a good platform to USE, everything is built well. My fav tool: data lineage (few clicks and you have ur schedule), contour (good for quality check, building dashboard), data preview (check stats data in few seconds)\n\nBUT it's not good for me as a data engineer. I can only use spark, a bit sql. Tech stack is so limited, you won't learn much about the architect, optimize resource, ..", "author": "No-Organization-7140", "created_utc": "2024-06-09 16:01:23", "permalink": "/r/dataengineering/comments/1d9ml0p/experience_with_palantir_as_a_data_engineer/l7twlka/"}
{"body": "Agreed, but Redshift competetitors will just do all that automatically. Or at least better out of the box", "author": "warclaw133", "created_utc": "2024-06-09 15:58:35", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tw4rm/"}
{"body": "There was this company which went bankrupt because they got a huge bill from Snowflake. So there are alternatives, but they are also expensive. Besides, \u201cRedshift is slow\u201d is a very vague and subjective statement. What use case and volume is it slow for?", "author": "AnonymousGiant69420", "created_utc": "2024-06-09 15:57:16", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tvww6/"}
{"body": "I think the best place to start if you are thinking about using redshift is the [Redshift Research Project ](https://www.redshiftresearchproject.org/white_papers/downloads/introduction_to_the_fundamentals_of_amazon_redshift.pdf)\n\n&gt; I am of the view about 95% of clients using Redshift should not be, and should\rbe on a different database, and the reason they get away with using Redshift is\rbecause they do not in fact have Big Data; they have small data, and as such\ras in a position where the hardware overwhelms the data and so they can do\rpretty much anything and so it all runs in a second or two and no is any the\rwiser.", "author": "Touvejs", "created_utc": "2024-06-09 15:56:39", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tvt4q/"}
{"body": "Yeah that's my point isn't it? More modern query engines like Presto would be smart enough to analyse the query without needing extra development overhead, and still be hundred times faster than redshift.", "author": "my_universe_00", "created_utc": "2024-06-09 15:53:56", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tvcd9/"}
{"body": "Why is it slow for you? My org handles trillion row tables with queries &lt; 500ms", "author": "ReporterNervous6822", "created_utc": "2024-06-09 15:50:27", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7turbu/"}
{"body": "It\u2019s not slow if you put time into your distribution style, sort keys, and compression", "author": "ReporterNervous6822", "created_utc": "2024-06-09 15:49:09", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tujq6/"}
{"body": "Management often thinks that anything bigger than  an excel spreadsheet is big data", "author": "McWhiskey1824", "created_utc": "2024-06-09 15:48:45", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tuhdu/"}
{"body": "Right? I\u2019ve extensively used Snowflake, Redshift, and BigQuery they all solve the same problem. Redshift gives more control but requires more tinkering. It has some pros like Redshift Spectrum if your team uses the Glue Catalog. I wouldn\u2019t bother migrating between, time/money would be better spent optimizing queries or data modeling.", "author": "McWhiskey1824", "created_utc": "2024-06-09 15:45:40", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ttyy5/"}
{"body": "We're on Redshift and happy with it.\n\nIt's on the slower side vs. its alternatives but it's the cheapest warehouse out there (by a lot) and if you properly use distribution and sort strategies on your data models, it's performant enough for our use cases (BI, analysis, modelling, etc ...).\n\nWe initially picked it for its fixed price, its close relationship with PostgreSQL and because our data collection system was in AWS.\n\nNot planning on changing anything atm.", "author": "thickmartian", "created_utc": "2024-06-09 15:44:08", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ttpsg/"}
{"body": "I did a transition this year from being an oracle dba for last 2 years to a DE. \nWork on sql alot of sql.\nPractice pyspark questions on databricks.\nI did 2 certifications- AWS SAA and AWS DE.\nPracticed alot of pyspark and sql questions on stratascratch around 300-350.\n\nMade 2-3 projects on aws and databricks and then made a big project which costed me around 25-30 dollars on aws.\n\nBasic skills: python, sql, pyspark, snowflake/Hive , Data warehouse concepts, pyspark theoretical concepts and databricks.\n\nShowed my 2 years of experience as big data developer and not a dba. \n\nYou can follow it step by step", "author": "Low_Falcon_2757", "created_utc": "2024-06-09 15:32:50", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7tru4n/"}
{"body": "Work at a somewhat small fintech startup (data team of 3).\n\n&gt;Are you looking to migrate away from Redshift?  \n\n\nBeing really honest, we are very willing to move off Redshift. But a thing that paralyzes the team is that our BI is almost all SQL written by analysts that have no performance in mind. So taking this to Snowflake or BigQuery might just increase spend way too much. Have heard a few \"horror\" stories.\n\n&gt;  \nIs it difficult finding engineers with Redshift expertise or engineers willing to work at a company that uses Redshift?  \n\n\nNot where we are,  quite a few have worked with Redshift, especially the most experienced engineers. We don't specify the DW in the job description, but few seem to care when we say we use it. Way more common to see people with experience in BigQuery.\n\n&gt;Data engineers would you take a job if company was using Redshift?  \n\n\nMaybe too obvious, but that's not a top priority for me when talking to a company. Feel like it would nice to work with Snowflake or other DW that actually cares about their product, but I look for other characteristics first.", "author": "m3-bs", "created_utc": "2024-06-09 15:30:38", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7trgxj/"}
{"body": "Most DWH SaaS host data warehouse on your choice of Cloud Provider. So if you let\u2019s say use Snowflake or Databricks, you are still technically on AWS. Both have better UX compared to Redshift.", "author": "CrowdGoesWildWoooo", "created_utc": "2024-06-09 15:19:35", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tpnje/"}
{"body": "Do people's expectations of you and your work change? Like, do they expect you to have deep technical knowledge about all the tools you're using right off the bat? Is it frowned upon if you need to research a couple of hours before answering a technical question?", "author": "RockLeeBaiano3000", "created_utc": "2024-06-09 15:12:04", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7tofo5/"}
{"body": "Yeah if there are entry-level jobs for DE. Looking for one for the past 2 months. Most, if not all, require some experience AND mandatory data tech stack, not only python and sql. But Im not complaining, pushing till I find the right one. Just wanted to state what the situation is rn", "author": "kateru6kata", "created_utc": "2024-06-09 15:09:50", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7to2t0/"}
{"body": "I think it's just super slow, and also based on a version of postgresql that's been around for 15 years. The query engine is not smart and forced developers in my team to work on very trivial stuff to make things work.", "author": "my_universe_00", "created_utc": "2024-06-09 15:09:07", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tnyp7/"}
{"body": "Should look into using apache flight\u00a0", "author": "startup_biz_36", "created_utc": "2024-06-09 15:05:05", "permalink": "/r/dataengineering/comments/1dbrb67/data_pipelines_with_duckdb/l7tnb9y/"}
{"body": "your to post implies that there is something wrong with Redshift. can you elaborate why you gave the perception that engineers would not consider working for a company using redshift? and why those on Redshift need a plan???", "author": "caksters", "created_utc": "2024-06-09 15:03:00", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tmzhi/"}
{"body": "same... 100% nobody is telling me what to do... they just accept my solutions if they work. Nobody is asking me to deliver X, Y and Z tasks by certain date... they just tell me their issues or their scenarios. A big con here cause I need frames of references, most of the times these were other peers pushing back or arguing against certain opinion or solution I provided, but without peers at your level in a certain project, you don't get this at the technical level, you do when talking with the stakeholders, when is too late. For me is literally the \"pin the tail on the donkey\" game... you pin the tail and lift your blindfold and see how far you were from the target, and correct your trajectory and try again. You design some data solution, you start executing and then you find out your wife left you and you were laid off and you car has been towed.", "author": "morpho4444", "created_utc": "2024-06-09 14:50:49", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7tl21k/"}
{"body": "That would be the other reason - it was the suggested architecture from the (AWS) \"solutions architect\" AKA salesperson.", "author": "warclaw133", "created_utc": "2024-06-09 14:50:28", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tl01m/"}
{"body": "If you were promoted, you are doing it already. If you switched job to a higher title, be ready to take in more management elements around your main job.", "author": "karrystare", "created_utc": "2024-06-09 14:43:29", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7tjwi7/"}
{"body": "I do the same stuff, I just have much more independence.", "author": "ilikedmatrixiv", "created_utc": "2024-06-09 14:39:21", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7tj95f/"}
{"body": "Currently have our BI reporting tools on Tableau + redshift backend but the performance has been lacking. First we\u2019ll try to optimize what we have in redshift and if that doesn\u2019t work, we will surely migrate. We have a veeeeery small cluster (2X small I think) and only tables between 10Go to 1To.", "author": "Cyliad", "created_utc": "2024-06-09 14:32:46", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7ti7zw/"}
{"body": "They didn't. I only get a new title lol.", "author": "Beneficial_Nose1331", "created_utc": "2024-06-09 14:32:45", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7ti7yb/"}
{"body": "This was our main reason for choosing redshift. It was the path of least resistance for mgmt.\n\nAlthough I will say some portion of the decision was based on the Kool-aid from the AWS rep (ex zero ETL)", "author": "truancy222", "created_utc": "2024-06-09 14:30:36", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7thvve/"}
{"body": "We took over a company that used redshift without bigdata. Management fell for the marketing I guess. Right now we are putting out fires when they appear but in my sector change is slow", "author": "Budget_Sherbet", "created_utc": "2024-06-09 14:29:36", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7thqis/"}
{"body": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "author": "AutoModerator", "created_utc": "2024-06-09 14:25:13", "permalink": "/r/dataengineering/comments/1dbuxqz/how_did_your_work_change_when_you_became_a/l7th2op/"}
{"body": "We migrated away from redshift, but not necessarily from the technology. We migrated away from a data warehouse architecture that hit its limit. We could've built it on redshift, but we chose to build it on Snowflake.", "author": "figshot", "created_utc": "2024-06-09 14:24:13", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tgx6d/"}
{"body": "Reason a prior company went with Redshift - it's AWS's data warehouse. That's the only reason. Would not consider alternatives. They were an AWS shop so that's what they used, and only what they used. \n\nI think they could have had a cheaper or easier solution but that wasn't the priority I guess.", "author": "warclaw133", "created_utc": "2024-06-09 14:20:54", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tgeu8/"}
{"body": "Am I out of the loop? Why do we need a plan?", "author": "bendgame", "created_utc": "2024-06-09 14:17:18", "permalink": "/r/dataengineering/comments/1dbucey/those_on_redshift_whats_the_plan/l7tfvd6/"}
{"body": "Simplicity. You want the fewest tools and frameworks that make the job easy to complete.", "author": "redditreader2020", "created_utc": "2024-06-09 14:06:52", "permalink": "/r/dataengineering/comments/1da910n/what_reasons_do_i_have_to_keep_any_data_in/l7tec8c/"}
{"body": "2025\n\n    from os import ai", "author": "crazyb14", "created_utc": "2024-06-09 13:44:36", "permalink": "/r/dataengineering/comments/1dboo9l/2010_2017_ml_pip_install_scikitlearn_2017_2023_ml/l7tb5km/"}
{"body": "If you do these projects and present them in front of recruiters at events/career fairs I\u2019d say you\u2019re at good chance of finding matches", "author": "Bosschopper", "created_utc": "2024-06-09 13:43:48", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7tb1i4/"}
{"body": "I\u2019m not sure how useful I\u2019d be as I\u2019m only 5 YoE, self taught and have only ever worked at one company.", "author": "likes_rusty_spoons", "created_utc": "2024-06-09 13:43:30", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7tb02o/"}
{"body": "Which services of aws in particular for DE?", "author": "Lost_in_problems", "created_utc": "2024-06-09 13:31:18", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7t9beo/"}
{"body": "I think you\u2019re overthinking it. Data engineer can be an entry level role if you\u2019re solid at Python and SQL. Nobody expects an undergrad to be turning up with 10 years experience.", "author": "LactatingBadger", "created_utc": "2024-06-09 13:28:46", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7t8z4a/"}
{"body": "This is exactly why dates, months, and years should be stored in separate columns until the data is served to the end user", "author": "Old-Personality7953", "created_utc": "2024-06-09 13:27:27", "permalink": "/r/dataengineering/comments/1dbfkmd/timestamp_column_has_multiple_formats/l7t8sqa/"}
{"body": "Hi, I am in the UK and cannot land even interview with 9 YoE. May I DM you to discuss? I believe there is something wrong with my CV.\n\nMany thanks!", "author": "BubblyImpress7078", "created_utc": "2024-06-09 13:24:16", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7t8def/"}
{"body": "Move your parameters to Azure SQL or postgres SQL and call it metadata. Use a lookup activity in ADF to read them back in ADF.", "author": "JoladaRotti", "created_utc": "2024-06-09 13:17:38", "permalink": "/r/dataengineering/comments/1db5ke6/how_to_efficiently_manage_parameters_in_adf/l7t7i2c/"}
{"body": "2025: \"Create a classification model. Save in the \"models\" folder. Use pytorch. Turn on the RGBs while you train the model (looks cool). After you are done use it to build a web app as well to test. Deploy it in my aws please. Don't forget to write the CICD. THANKS\"", "author": "Ok_Cartographer5609", "created_utc": "2024-06-09 13:05:47", "permalink": "/r/dataengineering/comments/1dboo9l/2010_2017_ml_pip_install_scikitlearn_2017_2023_ml/l7t5yqj/"}
{"body": "No, just once process, but when running on k8s I started noticing I had a different behavior than expected and came across issues like this one: https://github.com/duckdb/duckdb/issues/6519", "author": "stefanondisponibile", "created_utc": "2024-06-09 13:03:11", "permalink": "/r/dataengineering/comments/1dbrb67/data_pipelines_with_duckdb/l7t5n1i/"}
{"body": "Couldn't have said it better my self, i hate being tied up to a vendor, moved into a new company they using dataflow drag and drop kind of shit in azure data factory and there's barely any code.\nNightmare", "author": "BusyCauliflower675", "created_utc": "2024-06-09 12:53:47", "permalink": "/r/dataengineering/comments/1d9o0sv/how_much_coding_do_data_engineers_do/l7t4gqu/"}
{"body": "Thank you :) Yea I wanted to see how DuckDB would perform without any optimization on a \"rough\" query.\n\nah interesting, do you mean you have other processes running within the containers where you run duckdb? I typically like to only run one data process per container and when done spin down.", "author": "joseph_machado", "created_utc": "2024-06-09 12:50:56", "permalink": "/r/dataengineering/comments/1dbrb67/data_pipelines_with_duckdb/l7t4445/"}
{"body": "Thanks for the detailed reply", "author": "Standard-Alfalfa6501", "created_utc": "2024-06-09 12:45:12", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7t3ey7/"}
{"body": "Other things to look out for, for example, could be how duckdb performs within containers. I've run some workloads on Kubernetes where using duckdb's ability to limit e.g. memory or number of threads becomes challenging (there are some open issues about that). Or tricks like using \"preserve_insertion_order\", like they explain in their tuning guide. Good job anyway, and long live to duckdb :)", "author": "stefanondisponibile", "created_utc": "2024-06-09 12:41:05", "permalink": "/r/dataengineering/comments/1dbrb67/data_pipelines_with_duckdb/l7t2vj7/"}
{"body": "I worked in the industry for over a year. I am self taught in data analytics.\n\nI can't recall hearing about IBM certifications. \n\nSkills you may want to learn will include AWS, DBT (Data Build Tool), Snowflake, etc. Python and SQL are of course important foundations.\n\nAn impressive portfolio is one of the most important things.", "author": "gregTheEye", "created_utc": "2024-06-09 12:35:32", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7t26ck/"}
{"body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "author": "AutoModerator", "created_utc": "2024-06-09 12:34:18", "permalink": "/r/dataengineering/comments/1dbsprj/most_interesting_data_blogs_to_read/l7t20k4/"}
{"body": "all facts", "author": "stefanondisponibile", "created_utc": "2024-06-09 12:27:00", "permalink": "/r/dataengineering/comments/1dboo9l/2010_2017_ml_pip_install_scikitlearn_2017_2023_ml/l7t14c9/"}
{"body": "Any recommendations for all of those you mentioned?", "author": "Commercial-Ask971", "created_utc": "2024-06-09 12:25:31", "permalink": "/r/dataengineering/comments/1d9y1ao/what_swe_skills_do_i_need_to_lvl_up/l7t0yci/"}
{"body": "Generally yes, you can use file system as KV store, but performance will be magnitudes slower than a real KV stores due to multiple reasons.\n\nFor single machine use case, a dedicated disk-based KV store like RocksDB will perform much better.\n\nFor multi machine use case, self hosting Cassandra/ScyllaDB/HBase can be a cost effective solution as well.", "author": "random_lonewolf", "created_utc": "2024-06-09 12:23:34", "permalink": "/r/dataengineering/comments/1db88q6/key_value_conundrum/l7t0pug/"}
{"body": "Your post/comment was removed because it violated rule #3 (Do a search before asking a question). The question you asked has been answered in the wiki so we remove these questions to keep the feed digestable for everyone.", "author": "dataengineering-ModTeam", "created_utc": "2024-06-09 12:11:54", "permalink": "/r/dataengineering/comments/1dbr8ll/transitioning_from_a_bi_analystdev_role_to_a_de/l7szexz/"}
{"body": "I think it\u2019s a great plan to get a breadth of fundamental skills. Others are giving good ideas for fine-tuning the strategy. I want to share what I have seen candidates do, when reviewing applications for an entry-level position for those who lack professional experience. Some resumes arranged personal or school projects the way others would arrange work history. In fact, sometimes I felt this gave me an even better understanding of their relevant skills than the work history of others. Those commenters who have recommended building a portfolio of personal projects are giving solid advice, I think. This will give you a chance to apply the skills you are learning in the context of a problem.\n\nIt\u2019s a tough market out there, but you are clearly motivated to succeed.  Keep up the good work, and best of luck!", "author": "LowDownAndShwifty", "created_utc": "2024-06-09 12:11:35", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7szdpo/"}
{"body": "So, I'm not experienced, so take my other comment with a grain of salt, okay? It would probably be best to ask some seniors and stuff, but this was my reality of getting hired in 2024.\n\nI think they are really looking for people who not only got the basics down but are genuinely into learning. I talk passionately about my projects, and it catches the interviewers' attention (my manager actually said that after I was hired).", "author": "tinycockatoo", "created_utc": "2024-06-09 12:07:01", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7syvna/"}
{"body": "I had some python experience, a tiny bit of R and a little bit of matlab. The company that hired me mostly used R for their setup. They gave me a small take home assignment that I solved in python. It wasn't anything big, basically just fitting a function to some data. My solution wasn't perfect but showed that I could figure shit out on my own and they hired me.\n\nLooking back, that company was actually a pretty rinky dink operation, but I learned a lot. One of my colleagues was very competent and helped me pick up a lot of fundamentals of data engineering.\n\nAs for skillset, it was an understanding of basic data concepts (transformations, structures etc) and I think most importantly being able to show you can figure stuff out independently. I don't want to sound too full of myself, but if I can learn physics, I'm pretty sure I can easily learn whatever some company is doing.", "author": "ilikedmatrixiv", "created_utc": "2024-06-09 12:05:15", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7syoqf/"}
{"body": "once you start working .. you'll get more clarity.. so far you are doing all the right things .. go on", "author": "ab624", "created_utc": "2024-06-09 12:04:39", "permalink": "/r/dataengineering/comments/1dbr8ll/transitioning_from_a_bi_analystdev_role_to_a_de/l7symbf/"}
{"body": "Currently, we do not allow job postings in this subreddit. Please use r/dataengineeringjobs instead.", "author": "dataengineering-ModTeam", "created_utc": "2024-06-09 12:03:58", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7syjn6/"}
{"body": "Speaking for myself (got hired as a jr DE this year): relational databases and all their fundamental concepts; data warehouse and modeling; difference between batch and streaming; be able to namedrop some services/products and what they are used for; minimal contact with a big cloud provider (I did a big college project using my Azure free credits); machine learning basic concepts (idk why exactly); and the most important: SQL!!! LOTS of SQL concept questions.\n\nThey also asked me about Pyspark and OOP, but I was honest about the fact that I didn't know much about it.\n\nAll of this I learned at college. I think the best way to learn is through end-to-end data engineering projects, using the free cloud credits that Azure, AWS and GCP offer to students.\n\nYou can start by taking a big table from a Kaggle dataset and modeling a data warehouse by normalizing it. Use Postgres to create the data warehouse using SQL (all the tables and relationships). Create a Python (pandas is usually enough) script that takes some data from the cloud, does the necessary transformations, and loads the data into the DW. Now, think about some cool business questions you could answer about the dataset. Connect your DW to a dashboard-making thing (Tableau, Power BI, doesn't matter), and create some visualizations.\n\nNow you have a cool project you can put it in your resume and talk about in interviews.\n\nA second, even cooler project, is to create a data lakehouse. You can do this easily using Databricks Community (free) + some cloud provider. You need to understand the medallion architecture. Create scripts that will take raw data from the cloud, transform it, and load in the bronze, silver, and gold layers. Connect your gold layer to the dashboard tool of your choice and do a cool dashboard. Connect your silver layer to a Jupyter notebook and do some basic machine learning analysis. Do all the code in Pyspark. The syntax is very similar to pandas, and in Databricks, you shouldn't really worry about setting up Spark clusters and stuff.\n\nI think doing this and actually UNDERSTANDING what you're doing should be enough. Your basic data concepts game should be very strong, so this is the first step if you're not there yet.\n\nIf you already did all of this and are not getting interviews, this sucks, I know the market is tough rn. Luck plays a big role. Always try to customize your resume to the role, using the keywords present; you might not even be passing the initial AI filter. ChatGPT is useful for this: you can give it a job description and ask him to make a fake resume of the ideal candidate, them try to use this template for yours.\n\nedit: changed POO to OOP. I mixed up my native language lol", "author": "tinycockatoo", "created_utc": "2024-06-09 11:59:52", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7sy3o9/"}
{"body": "Beware: if you want to work for companies in the US duble taxation could be an issue", "author": "Agreeable_Bake_783", "created_utc": "2024-06-09 11:53:56", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7sxgo0/"}
{"body": "We are using redshift and actively researching iceberg with starburst or athena as a potential replacement. \u00a0I don\u2019t have experience with snowflake. Our redshift schemas are built on the fly for additive changes via script generation on the daily or monthly parquet files we ingest. \u00a0We detect breaking changes and require a cutover when those occur, but they are planned.", "author": "vandelay82", "created_utc": "2024-06-09 11:49:57", "permalink": "/r/dataengineering/comments/1dbh929/terraform_vs_opentofu/l7sx1m6/"}
{"body": "Are you interested in transitioning into Data Engineering? Read our community guide: https://dataengineering.wiki/FAQ/How+can+I+transition+into+Data+Engineering\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "author": "AutoModerator", "created_utc": "2024-06-09 11:05:50", "permalink": "/r/dataengineering/comments/1dbr8ll/transitioning_from_a_bi_analystdev_role_to_a_de/l7ssnt6/"}
{"body": "Can you point out the skillset you had when you were selected for the junior role? On job descriptions it seems like a bit broader and too much for a starter role.It would have been nice to get a realistic comment from someone who actually started as a junior DE", "author": "Standard-Alfalfa6501", "created_utc": "2024-06-09 10:56:13", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7srsbg/"}
{"body": "I never had a formal education in DE. I have a degree in physics and did some programming during my studies, most of which was self taught. I then started in a junior role and learned everything on the job. I'm a bad reference for official resources.", "author": "ilikedmatrixiv", "created_utc": "2024-06-09 10:51:15", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7src67/"}
{"body": "Where can we achieve maximum understanding of basics? Can you share any resources like standard textbooks or courses?", "author": "Standard-Alfalfa6501", "created_utc": "2024-06-09 10:42:15", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7sqjm2/"}
{"body": "You get 400eur in free credits from microsoft for a month and many resources have free trials. However, there is always a risk with personal cloud subscriptions of spinning up something really expensive and noticing.", "author": "Annual_Scratch7181", "created_utc": "2024-06-09 10:35:09", "permalink": "/r/dataengineering/comments/1dbqca5/azure_data_engineering_subscription/l7spxic/"}
{"body": "The basic cloud certifications are kind of useless in my opinion. I have some of them (AWS and Azure) and if I would hire someone, the presence of said certs would not act as a benefit for me personally. If the applicant would emphasize the certs, it would even be a deterrent.\n\nThey don't test your skills or knowledge as a DE, they test how well you know the different products of the cloud provider. I am unfamiliar with IBM certs, so I can't comment on their usefulness.\n\nFor me personally, what I would look for in a junior is understanding of important concepts. E.g. how certain transformations work, how they would use different datasets to get certain information out of them, the concept of normalization etc. If you understand the basics, putting them into practice isn't all that difficult.", "author": "ilikedmatrixiv", "created_utc": "2024-06-09 10:26:52", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7sp86y/"}
{"body": "I think having a personal blog and some projects on github that you put in your CV will maximise the chances to get interviews.", "author": "youngnight1", "created_utc": "2024-06-09 10:06:11", "permalink": "/r/dataengineering/comments/1dbpj3i/is_it_possible_to_become_a_data_engineer_in_6/l7sniim/"}
{"body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "author": "AutoModerator", "created_utc": "2024-06-09 10:04:02", "permalink": "/r/dataengineering/comments/1dbqca5/azure_data_engineering_subscription/l7snc4o/"}
{"body": "With 7 years of data analysts experience I don\u2019t think it will be difficult to transition into DE. With your current role you must to familiar with DHW concepts (if not then you have a problem), along with it you need to up skill in \n- data engineering concepts \n- data pipeline architecture \n- anyone of programming languages that support advance data engineering (Java, python, scala,go) and python is easy to start. \n- Cloud technologies and containers is good but a must.\n- understanding of GIT\n- do some hands on project and show it in your profile.\n\nHere are some basics that I wrote, hope it helps you. Good luck.\n\nhttps://medium.com/@syedkadaransari/demystifying-data-pipelines-architecture-types-design-patterns-and-recommendations-part-1-107d0fd58202\n\nhttps://medium.com/@syedkadaransari/demystifying-data-pipelines-architecture-types-design-patterns-and-recommendations-part-2-856846038ecc\n\nhttps://medium.com/@syedkadaransari/data-warehousing-best-practices-principles-for-designing-effective-data-storage-systems-e8093814a14e\n\nhttps://medium.com/@syedkadaransari/7-things-i-wish-i-had-known-as-a-junior-data-engineer-9686c4f66251", "author": "OmuaOmua", "created_utc": "2024-06-09 08:53:05", "permalink": "/r/dataengineering/comments/1da5ztr/any_tips_for_breaking_into_the_field/l7shmrb/"}
{"body": "I think your range is reasonable. Although it depends if you are looking for a permanent position or contracting position and what country.... I have found contracting to be far more lucrative until the economy shit itself recently, and funding is getting cut.", "author": "Bootlegcrunch", "created_utc": "2024-06-09 08:41:02", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7sgo3m/"}
{"body": "You can already see that [here](https://github.com/KamilKolanowski/rick_morty_api_analysis) :)", "author": "tanssive", "created_utc": "2024-06-09 08:35:36", "permalink": "/r/dataengineering/comments/1d9rtes/rick_and_morty_data_analysis_with_polars/l7sg8cj/"}
{"body": "Meta uses Spark and ORC in their analytics space. Of course some SQL tools for sure as well.\n\nhttps://medium.com/@AnalyticsAtMeta/data-engineering-at-meta-high-level-overview-of-the-internal-tech-stack-a200460a44fe", "author": "dustinBKK", "created_utc": "2024-06-09 08:28:43", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7sfogl/"}
{"body": "original post: [https://www.linkedin.com/posts/julienhuraultanalytics\\_2010-2017-ml-pip-install-scikit-learn-activity-7203719665326419969-xuKc](https://www.linkedin.com/posts/julienhuraultanalytics_2010-2017-ml-pip-install-scikit-learn-activity-7203719665326419969-xuKc)", "author": "Economy-Spread1955", "created_utc": "2024-06-09 08:05:57", "permalink": "/r/dataengineering/comments/1dboo9l/2010_2017_ml_pip_install_scikitlearn_2017_2023_ml/l7sdtbm/"}
{"body": "I mean, you could count adversarial search as \u201cAI\u201d, it doesn\u2019t include evaluating probabilities. Albeit it\u2019s very basic, but I\u2019d still count it as AI", "author": "pioverpie", "created_utc": "2024-06-09 07:57:47", "permalink": "/r/dataengineering/comments/1d9s2qe/what_are_everyones_hot_takes_with_some_of_the/l7sd4xd/"}
{"body": "In\u200b my\u200b country, seems\u200b DE\u200b can\u200b not\u200b be\u200b enought", "author": "Icy-Ad-6789", "created_utc": "2024-06-09 07:39:37", "permalink": "/r/dataengineering/comments/1b7fcgo/is_everyone_becoming_a_data_engineer_and_is_it/l7sbmre/"}
{"body": "I would say if you chunk your data into reasonable partitions based on a formula for a key you could make it  fast", "author": "Sufficient_Example30", "created_utc": "2024-06-09 07:29:20", "permalink": "/r/dataengineering/comments/1db88q6/key_value_conundrum/l7sarpn/"}
{"body": "Not 100% related to Databricks cost but spinning off 100+ jobs is probably incurring elevated VMs cost. Have you considered running multiple jobs within the same cluster ? Magic commands will help to execute py files or notebooks within another file/notebook.", "author": "RoundReveal", "created_utc": "2024-06-09 07:03:38", "permalink": "/r/dataengineering/comments/1dae1uz/how_did_you_reduce_your_databricks_costs/l7s8kp1/"}
{"body": "Yeah, the main reason I split it into two tables instead of leaving it as one and relying on compression is because I wanted the metadata history to be stored separately from the stats history. \n\nThis way you can easily query the metadata history table and just see rows if the index has ever been altered or changed...Things like fill factor, padding, disabled, etc. Whereas the stats history table will have multiple records per day going back about 6 months for the same index.\n\nIt does make things a bit difficult because now you can't easily align index metadata status with stats history records, but that's really not much of a concern. \n\nAs far as the row groups, it seems to be ok. The process runs about twice a day where it inserts roughly 7,500 records 450 times in the span of a few minutes. And SQL Server relies on those row groups to perform the auto deletes from the history table. \n\nPerformance seems to be pretty good though. This isn't the type of system where queries need to return within a second for an app or anything. So as long as they are running within a minute or so, I'm not going to bother fine tuning it or doing any huge refactoring.", "author": "chadbaldwin", "created_utc": "2024-06-09 06:54:55", "permalink": "/r/dataengineering/comments/1d92cm0/discussion_i_built_a_tool_for_analyzing_sql/l7s7tgl/"}
{"body": "I'll have to look into that. I'm not too familiar with time series databases. I've messed around with Prometheus and Grafana just a tiny bit years ago with playing with Pi-Hole. I've also heard of InfluxDB, but never used it. Though a lot of people use it for Home Assistant, so maybe I'll migrate my smart home stuff over to learn how to use it.\n\nI suppose technically you could say that Splunk is a time series database which supports direct JSON loading.\n\nI did try to build this originally with Splunk, but unfortunately it just didn't scale well.\n\nThat said, due to how SQL Server stores these statistics, I would assume there's no way around the pre-processing, right? \n\nFor example...SQL Server stores the number of read operations per index as a counter. That counter continues to go up forever and only ever resets when the service/host restarts, or the database is restored (and a couple other weird cases).\n\nSo my current system calculates a best guess approximation of how old the statistics are, because SQL server doesn't tell you. And then it figures out whether to calculate the delta (difference between the two snapshots), or to take the stats as-is, because the stats were reset at some point since the previous snapshot, so there's no delta to calculate.\n\nIf you don't pre-process, then you have to do all that on the fly as a streaming function, which seems like a waste of compute power.", "author": "chadbaldwin", "created_utc": "2024-06-09 06:46:54", "permalink": "/r/dataengineering/comments/1d92cm0/discussion_i_built_a_tool_for_analyzing_sql/l7s73tc/"}
{"body": "You\u2019re comparing yourself to a very small sample of people who have actually read and understood the book. I would instead compare yourself to a much larger sample who say they want to improve their data skills but never actually do anything about it. You\u2019ve done the hard work and now you\u2019ve got the theory to apply in practice that many don\u2019t! Well done!", "author": "GlueSniffingEnabler", "created_utc": "2024-06-09 06:40:23", "permalink": "/r/dataengineering/comments/1dbax05/how_long_did_it_take_you_to_read_database_system/l7s6iue/"}
{"body": "Pretty sure you shouldn\u2019t find it hard finding a UK job that pays more. I\u2019m remote, senior DE in the UK, get paid 10k more than you and that\u2019s still below market rate.", "author": "likes_rusty_spoons", "created_utc": "2024-06-09 06:38:36", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7s6d1y/"}
{"body": "Thanks! I'm definitely proud of the project...I just wish I knew more about more modern tools that data engineers use. I feel so behind building everything with PowerShell, C# and SQL Server... Don't get me wrong, it works great, I just feel like I'm falling behind/missing out.", "author": "chadbaldwin", "created_utc": "2024-06-09 06:36:12", "permalink": "/r/dataengineering/comments/1d92cm0/discussion_i_built_a_tool_for_analyzing_sql/l7s65c6/"}
{"body": "We version control and utilize CI/CD for azure data factory. You just need to choose to do it.", "author": "droosif", "created_utc": "2024-06-09 06:20:06", "permalink": "/r/dataengineering/comments/1d9o0sv/how_much_coding_do_data_engineers_do/l7s4pl2/"}
{"body": "Yeah, OP spent more time writing this thread than writing those joins", "author": "UpstairsEye4793", "created_utc": "2024-06-09 06:12:24", "permalink": "/r/dataengineering/comments/1dafb24/sql_query_help/l7s40hf/"}
{"body": "provide more details", "author": "ab624", "created_utc": "2024-06-09 06:05:44", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7s3ekp/"}
{"body": "US companies look for work.permit visas and generally won't accept to let their data operated outside continent. More over there are lots of highly skilled DEs within US", "author": "rajekum512", "created_utc": "2024-06-09 05:55:38", "permalink": "/r/dataengineering/comments/1dbmc5i/looking_for_a_remote_job_as_senior_de/l7s2h7q/"}
{"body": "all, I'm not part of the decision maker so i dont know the rationality and dont really have a say about it. Im more on the part of implementing it and maintaining it.\n\nWith the other folks that think we should not, can you share why or the problems you had why youre against it?", "author": "elijahlucas829", "created_utc": "2024-06-09 05:46:02", "permalink": "/r/dataengineering/comments/1db3a6m/redshift_implementation/l7s1jz6/"}
{"body": "They give you a really good interview guide (best I have ever seen), it's just lists/dicts/arrays.\u00a0", "author": "lastchancexi", "created_utc": "2024-06-09 05:34:13", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7s0f86/"}
{"body": "I would pick EMR server less since it's closer to pure play EMR, and you are not lost in the aws specific glue abstractions. While the outcome is same in both cases, EMR will be a generic solution and portable to multiple platforms.", "author": "abhi5025", "created_utc": "2024-06-09 05:12:34", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7rycks/"}
{"body": "Just got involved in a project where we are using terraform 1.8.0 to provision aws components and also some snowflake. Migrated to dbt for the tables bc the terraform snowflake provider wasn\u2019t handling ddl changes well. But schemas and external stages are still in TF. What comes to your mind regarding this setup? What should i look into/research for long term?", "author": "Old-Evening9609", "created_utc": "2024-06-09 05:06:47", "permalink": "/r/dataengineering/comments/1dbh929/terraform_vs_opentofu/l7rxs36/"}
{"body": "Absolutely, don't do this!  You are adopting legacy tech. It is slow.  It is nowhere near as good as most of the other options.", "author": "discord-ian", "created_utc": "2024-06-09 05:02:31", "permalink": "/r/dataengineering/comments/1db3a6m/redshift_implementation/l7rxcqt/"}
{"body": "We have an ML model that can predict how long a query will take to run.", "author": "mirasume", "created_utc": "2024-06-09 04:26:25", "permalink": "/r/dataengineering/comments/1c5pcos/my_project_save_50_on_snowflake_in_15_minutes/l7rtln6/"}
{"body": "What kind of python tasks? Like pyspark or other?", "author": "gman1023", "created_utc": "2024-06-09 03:42:01", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7ropnc/"}
{"body": "for each row in the vulnerabiltiies table, there can be multiple groups since each host can be associated with multiple groups? if so, then you'd need to join vulnerabilities to host to group bridge table (many to many join) -- filtering for host-to-groups based on the row-valid columns -- and then aggregate afterwards.", "author": "yo_sup_dude", "created_utc": "2024-06-09 03:04:18", "permalink": "/r/dataengineering/comments/1darvjw/how_to_track_historical_aggregates_in_scd2_based/l7rk84m/"}
{"body": "I wouldn't compare them. Firestore is closer to Dynamo. I'd use BigTable more for very large scale time series and analytics use cases. Dynamo can power applications of all sizes. It's very likely being used for far more things where BigTable would be overkill.\n\nBigTable is also wide column oriented (think Cassandra or HBase) rather than key-value oriented like Dynamo or Firestore. I think AWS has a managed Cassandra option.", "author": "mailed", "created_utc": "2024-06-09 02:59:11", "permalink": "/r/dataengineering/comments/1d9hqoy/why_is_dynamodb_disproportionately_more_popular/l7rjjxa/"}
{"body": "Assuming they mean data structures and algorithms", "author": "Lower_Sun_7354", "created_utc": "2024-06-09 02:51:42", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7rilna/"}
{"body": "Wow that's really interesting, def not what I was expecting haha, thanks for the rec I'll absolutely take a look.", "author": "Ok-Carpet-2891", "created_utc": "2024-06-09 02:50:54", "permalink": "/r/dataengineering/comments/1dbe3j2/favorite_resources_related_to_project_management/l7rii3p/"}
{"body": "Thank you!", "author": "Few_Barber_8292", "created_utc": "2024-06-09 02:42:55", "permalink": "/r/dataengineering/comments/1dbh929/terraform_vs_opentofu/l7rhhln/"}
{"body": "DSA?", "author": "Uwwuwuwuwuwuwuwuw", "created_utc": "2024-06-09 02:31:17", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7rfzcd/"}
{"body": "Probably no need for Spark. Could probably just use Athena or even DuckDB for what you described.", "author": "pi-equals-three", "created_utc": "2024-06-09 02:30:36", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7rfw5v/"}
{"body": "Dont", "author": "Doyale_royale", "created_utc": "2024-06-09 02:28:39", "permalink": "/r/dataengineering/comments/1db3a6m/redshift_implementation/l7rfn3v/"}
{"body": "I would read *The Phoenix Project* to get your appetite whet on this topic. It's a fiction book written by folks who literally wrote the book on DevOps. Certainly not the end all on the topic, but I think it will introduce you to lots of topics you may want to explore further.", "author": "Known-Huckleberry-55", "created_utc": "2024-06-09 02:16:50", "permalink": "/r/dataengineering/comments/1dbe3j2/favorite_resources_related_to_project_management/l7re3x3/"}
{"body": "Do you really need Spark? You can run your tasks using ECS tasks in AWS.", "author": "Proud-Walk9238", "created_utc": "2024-06-09 02:16:34", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7re2nn/"}
{"body": "Thanks mate, I'll DM you", "author": "mailed", "created_utc": "2024-06-09 02:11:58", "permalink": "/r/dataengineering/comments/1d92m2s/what_are_some_rarely_explored_niches_in_data/l7rdgbi/"}
{"body": "What are you going to do about 01/02/2024? Is that Jan 2 or Feb 1? You'd need to detect across known data which is which for XX/ZZ/YYYY, such as only ZZ &gt;=12 so XX is months and format for that range is MM/DD/YYYY.\n\nIf this is known and its just you have \n\n2024-06-09T00:00:00Z  \nOr 2024-06-09 00:00:00.000-07:00  \n06/09/2024 00:00:00\n\nWith no month/day col ambiguity\n\nJust identify the format and timezone, and apply the correct transformations, whether SQL or Python, these are pretty standard so date helper functions exist and Python has some auto datetime formatters but can't speak to reliability", "author": "Monowakari", "created_utc": "2024-06-09 02:02:41", "permalink": "/r/dataengineering/comments/1dbfkmd/timestamp_column_has_multiple_formats/l7rc859/"}
{"body": "It\u2019s Columbus, OH\n\nI wish I asked for more, but I\u2019m also happy with what I have. Comparison is the thief of joy", "author": "BigSpartan84", "created_utc": "2024-06-09 02:02:38", "permalink": "/r/dataengineering/comments/1d5q7db/quarterly_salary_discussion_jun_2024/l7rc7us/"}
{"body": "EMR probably cheaper, glue prob easier to roll with", "author": "chrisrules895", "created_utc": "2024-06-09 01:47:47", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7ra8jd/"}
{"body": "are they giving up on delta ?", "author": "Electrical-Ask847", "created_utc": "2024-06-09 01:28:22", "permalink": "/r/dataengineering/comments/1da910n/what_reasons_do_i_have_to_keep_any_data_in/l7r7o9m/"}
{"body": "Don\u2019t use it. \nSpec out cost of data center and buy your own on-prem machines. The cost saving is staggering after a few years if your typical workload requires high memory spec host.", "author": "Adorable-Employer244", "created_utc": "2024-06-09 01:24:19", "permalink": "/r/dataengineering/comments/1dae1uz/how_did_you_reduce_your_databricks_costs/l7r74ot/"}
{"body": "Everything at Meta is internal. As a DE you would be working on something similar to Airflow + Presto/Spark and probably a few other things. The only thing they care about is Python and SQL.\n\nSource: Ex-Meta DE", "author": "Ok-Muffin-8079", "created_utc": "2024-06-09 01:18:25", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7r6cwc/"}
{"body": "Okay thanks so much!", "author": "Acrobatic_Sample_552", "created_utc": "2024-06-09 01:12:15", "permalink": "/r/dataengineering/comments/1db4j6e/how_do_you_configure_a_data_lake_to_connect/l7r5jem/"}
{"body": "I'm reading the official DMBOK book (the one you can physically kill a human being with), also with help of GPT.", "author": "Lemonade-Candy-121", "created_utc": "2024-06-09 01:11:51", "permalink": "/r/dataengineering/comments/1daznz3/are_there_anyone_preparing_for_cdmp_dmbok/l7r5hiu/"}
{"body": "\n1. SR BI Engineer.\n2. 2 YOE after officially pivoting to data only roles. This is after 6-7 years of more jack of all trades roles in IT which included business analysis and reporting duties, along with some implementation projects.\n3. Ohio (100% remote).\n4. 140k base.\n5. 10% of base. $75k in equity vested over 4 years.\n6. SaaS (but on the business side).\n7. Snowflake, DBT, Python, AWS.\n\nI started this role very recently. I'll be staying here as long as I can. It's a great company with room for growth. Previous role I was at 118k, no bonuses or equity, but still 100% remote.", "author": "cream_pie_king", "created_utc": "2024-06-09 01:09:57", "permalink": "/r/dataengineering/comments/1d5q7db/quarterly_salary_discussion_jun_2024/l7r58fm/"}
{"body": "You can get Carfax and Autocheck for only $10. [click here](https://www.paypal.com/ncp/payment/LHCZAWAZXDG3G)", "author": "FewProfessional3823", "created_utc": "2024-06-09 01:07:16", "permalink": "/r/dataengineering/comments/18s5vnb/how_does_carfax_get_all_of_its_data/l7r4vtv/"}
{"body": "I mean, the DE stack is pretty much custom-built Airflow, but they don't care about any of that in the interview.", "author": "lastchancexi", "created_utc": "2024-06-09 01:06:01", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7r4pxy/"}
{"body": "That's a great point regarding \"catching off guard.\" Thanks for your feedback!", "author": "on_the_mark_data", "created_utc": "2024-06-09 00:57:14", "permalink": "/r/dataengineering/comments/1d9zyas/how_would_you_like_to_learn_about_data_quality/l7r3k7b/"}
{"body": "IBM bought hashi Corp. \u00a0I wouldn\u2019t say IBM has been great as of late, but they know how to steam a corporate ham. \u00a0\n\nI would focus on using 1.5.7 and then it works either way. My team is on a much earlier version of TFE and we moved to Scalr last fall. \u00a0\n\nWe are a large fortune 50 company and are leaning open tofu, but I wouldn\u2019t say it\u2019s a total lock just yet. \u00a0", "author": "vandelay82", "created_utc": "2024-06-09 00:45:43", "permalink": "/r/dataengineering/comments/1dbh929/terraform_vs_opentofu/l7r215w/"}
{"body": "I'm going to take this opportunity to hate on dashboards, even if I'm alone in my hatred.\n\n\nScrew Power BI, and screw tableau, and screw Looker, and screw the rest of them too.\n\n\nI can understand that when you need to provide a place for other people to self-serve data, they can be a great hub. But when I need to glance over 40 metrics each week to see how they're ticking along, I find it much easier to have all 40 graphs laid out in Excel without the need for me to apply any filters or change views.", "author": "ColdStorage256", "created_utc": "2024-06-09 00:28:40", "permalink": "/r/dataengineering/comments/1d9s2qe/what_are_everyones_hot_takes_with_some_of_the/l7qzqy6/"}
{"body": "You shouldn't need AI to tell you how many widgets you sold last year but it could be very useful in helping you answer \"How many widgets will we sell to Germany next year?\"", "author": "ColdStorage256", "created_utc": "2024-06-09 00:21:35", "permalink": "/r/dataengineering/comments/1d9s2qe/what_are_everyones_hot_takes_with_some_of_the/l7qysl0/"}
{"body": "5 week", "author": "CrayonUpMyNose", "created_utc": "2024-06-09 00:20:25", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7qymyt/"}
{"body": "FAANG does not care about tools. Just DSA + system design + behavioral.", "author": "boboshoes", "created_utc": "2024-06-09 00:06:21", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7qwqgp/"}
{"body": "As a Manager, Fabric is the primary choice because execs want to listen to a salesman vs. literally everyone that manages or uses the platform.", "author": "No_Cover_Undercover", "created_utc": "2024-06-08 23:50:23", "permalink": "/r/dataengineering/comments/1dan6w0/are_databricks_really_going_after_snowflake_or_is/l7qul7h/"}
{"body": "Meta\u2019s tech stack is entirely internally developed tools. They have a 2 week onboarding bootcamp where they teach them to you.", "author": "its_PlZZA_time", "created_utc": "2024-06-08 23:41:33", "permalink": "/r/dataengineering/comments/1dbf4xg/meta_tech_stack/l7qtdhi/"}
{"body": "Get really conversant in AWS/Azure/GCP (whatever your company uses) and how to build production quality apps. Learn Docker forwards and back. Understand messaging systems really well. Ever read DDIA? If not do.", "author": "AlgoRhythmCO", "created_utc": "2024-06-08 23:16:50", "permalink": "/r/dataengineering/comments/1dafrbc/what_should_i_focus_on_if_i_want_to_eventually/l7qpxz5/"}
{"body": "Check out [Zooniverse](https://www.zooniverse.org/). I haven't tried it myself but it seems that there are research projects which probably could do with some technical advice.", "author": "NASAOfficialAccount", "created_utc": "2024-06-08 23:13:11", "permalink": "/r/dataengineering/comments/1dbe8p1/i_would_like_collaborate_on_data_projects/l7qpftx/"}
{"body": "Glue itself runs on EMR. You have more features around it like crawler, dq stuff and its integration with Athena etc\n\nThink from use cases that will drive your needs", "author": "ZeroMomentum", "created_utc": "2024-06-08 23:06:30", "permalink": "/r/dataengineering/comments/1dbe4c0/choosing_between_aws_glue_and_emr_serverless_for/l7qoild/"}
{"body": "well, we are just pretty young in using adf and everyone developing the pipeline doesn't always follow best practices :)", "author": "spacehamba", "created_utc": "2024-06-08 22:51:24", "permalink": "/r/dataengineering/comments/1db5ke6/how_to_efficiently_manage_parameters_in_adf/l7qmer9/"}
{"body": "imply druid", "author": "Electrical-Ask847", "created_utc": "2024-06-08 22:44:21", "permalink": "/r/dataengineering/comments/1day6ka/these_companies_offering_a_cloud_premium_version/l7qlf8d/"}
{"body": "Try open source", "author": "CrowdGoesWildWoooo", "created_utc": "2024-06-08 22:31:45", "permalink": "/r/dataengineering/comments/1dbe8p1/i_would_like_collaborate_on_data_projects/l7qjnnj/"}
{"body": "Can you give a review of your first 3 weeks?", "author": "Spicy_Latina29", "created_utc": "2024-06-08 22:18:44", "permalink": "/r/dataengineering/comments/194304v/reviews_on_data_engineer_academy/l7qhu99/"}
{"body": "You can find our open-source project showcase here: https://dataengineering.wiki/Community/Projects\n\nIf you would like your project to be featured, submit it here: https://airtable.com/appDgaRSGl09yvjFj/pagmImKixEISPcGQz/form\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "author": "AutoModerator", "created_utc": "2024-06-08 22:13:41", "permalink": "/r/dataengineering/comments/1dbe8p1/i_would_like_collaborate_on_data_projects/l7qh4p4/"}
{"body": "&gt; Even though they show power bi and DF as inside the fabric boundary on heir diagrams.\n\nFabric has re-implementations of all of these items. Imagine they've forked the repo and integrated them into some all-inclusive package. The ADF you get in Azure is not the same as the one you get in Fabric, though it will be very similar.", "author": "azirale", "created_utc": "2024-06-08 22:08:09", "permalink": "/r/dataengineering/comments/1dan6w0/are_databricks_really_going_after_snowflake_or_is/l7qgccz/"}
{"body": "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*", "author": "AutoModerator", "created_utc": "2024-06-08 22:06:58", "permalink": "/r/dataengineering/comments/1dbe3j2/favorite_resources_related_to_project_management/l7qg6bx/"}
{"body": "There may be better ways to do this:\n\n   * Leverage the source system's transaction log: better for low-latency, the only solution if you need transaction-level changes, better for reducing impact to the source system, but worse for complexity: you really want a pre-built solution to support this.\n   * Source system publishes data that you then pick up:  better for creating a managed interface between two systems.\n\nRegarding the solution you've got a few things to consider:\n\n   * Timestamps on your upstream system may not be extremely precise: they may get assigned well before the transaction is actually committed.  The implication of this is that those rows may only become visible to your queries 3 seconds or 3 minutes AFTER the timestamp!  For this reason it's usually best to include some concept of a \"grace period\".  For example, modify your range to start at the end of the last query and end at the current time minus 3 to 5 minutes.\n   * I find that it's helpful to store the data I extract this was as part of my raw archive.  To make this most useful I have timestamps on each file and I ensure that no file spans a day or hour boundary.  So, it's easy to examine the data for any period of time - and possibly reprocess or reload it.\n   * Use an audit or control table to track what you've queried, how many rows returned, what the exact start/stop times are, what the actual process times are, and what the return codes are.  This can eliminate queries against the source system and give you easy reporting on how your system has been working.\n   * Consider building a tiny little reconciliation system:  something that counts rows after a period has been completed on both source &amp; destination and loads them into a table.  Then once there you can compare those rows to ensure they're identical - and you're not missing any entries.  Missing entries could be due to reprocessing by the source system, maybe their timestamps are applied at the app level and not very reliable, etc, etc.", "author": "kenfar", "created_utc": "2024-06-08 22:01:55", "permalink": "/r/dataengineering/comments/1db9bz8/best_practice_for_keeping_related_incremental/l7qfg1r/"}
{"body": "CrateDB seems like a good fit", "author": "surister", "created_utc": "2024-06-08 21:31:44", "permalink": "/r/dataengineering/comments/1daxd20/need_inputs_on_choosing_right_nosql_database_open/l7qb198/"}
{"body": "If you read the entire book in 3-4 months and actually understood all of the concepts in the book (note: most people who read the book don\u2019t really dive too deep), then yeah that\u2019s pretty impressive imo. Databases are an important topic and that book covers database at a much broader and deeper level than 90+% of devs need to know", "author": "yo_sup_dude", "created_utc": "2024-06-08 20:59:34", "permalink": "/r/dataengineering/comments/1dbax05/how_long_did_it_take_you_to_read_database_system/l7q65cu/"}
{"body": "I think the cloud strategy is better to base on your company's business requirement with certain stage and size. I can see many small to medium startups starting with managed data services provided by cloud vendors, such as GCP, AWS or Azure and I think all of them should be OK. But eventually, when a startup becomes a large company or acquired by a bigger company, then multi-cloud strategy comes after as you and your company would prefer to adopt a vendor neutral architecture rather than vendor-lockin. \n\nFor career prospective, yes, the experience with data infrastructure on multi-cloud is better than bet on any cloud only.", "author": "Brief_Waltz_6455", "created_utc": "2024-06-08 20:54:54", "permalink": "/r/dataengineering/comments/1dayxg5/what_cloud_strategy_we_should_start/l7q5fx8/"}
{"body": "A 4th table to control, especially if you have a common PK.", "author": "SirGreybush", "created_utc": "2024-06-08 20:54:40", "permalink": "/r/dataengineering/comments/1db9bz8/best_practice_for_keeping_related_incremental/l7q5emt/"}
{"body": "This post was flagged as not being related enough to data engineering. In order to keep the quality and engagement high, we sometimes remove content that is unrelated or not relevant enough to data engineering.", "author": "dataengineering-ModTeam", "created_utc": "2024-06-08 20:53:21", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7q57hg/"}
{"body": "OP: BigQuery outperforms its competitors in most use cases, both in speed and cost. I will say that GCP managed airflow is very rigid and limited, specially since you are already deploying your own, I would deploy my own airflow on GCP managed k8s. Also I would leverage k8s operator more since you would be already using it.", "author": "ALostWanderer1", "created_utc": "2024-06-08 20:12:30", "permalink": "/r/dataengineering/comments/1dayxg5/what_cloud_strategy_we_should_start/l7pywme/"}
{"body": "GCP is a natural fit, but AWS Glue can also be a great alternative.", "author": "Lost_Investigator297", "created_utc": "2024-06-08 20:10:38", "permalink": "/r/dataengineering/comments/1dayxg5/what_cloud_strategy_we_should_start/l7pymcm/"}
{"body": "I'm also studying for CDMP! What resources are you using to prep?", "author": "Lost_Investigator297", "created_utc": "2024-06-08 20:10:25", "permalink": "/r/dataengineering/comments/1daznz3/are_there_anyone_preparing_for_cdmp_dmbok/l7pyl7g/"}
{"body": "Have you considered Apache Cassandra for high write throughput and scalability?", "author": "Lost_Investigator297", "created_utc": "2024-06-08 20:10:11", "permalink": "/r/dataengineering/comments/1davs19/dynamodb_or_other_options/l7pyjtv/"}
{"body": "Have you considered OrientDB? It's scalable, NoSQL, and has sync capabilities.", "author": "Lost_Investigator297", "created_utc": "2024-06-08 20:09:29", "permalink": "/r/dataengineering/comments/1daxd20/need_inputs_on_choosing_right_nosql_database_open/l7pyg26/"}
{"body": "Check out MongoDB's success, it's a great example of OSS + premium cloud model.", "author": "Lost_Investigator297", "created_utc": "2024-06-08 20:09:15", "permalink": "/r/dataengineering/comments/1day6ka/these_companies_offering_a_cloud_premium_version/l7pyeqo/"}
{"body": "Everyone has its own pace, nonetheless I believe that going through such hard and long piece of knowledge, with properly understanding it in timespan you mentioned is pretty good, and the best thing is you had a discipline to go through it :)\n\nKeep it up!", "author": "Natural-Tune-2141", "created_utc": "2024-06-08 20:07:24", "permalink": "/r/dataengineering/comments/1dbax05/how_long_did_it_take_you_to_read_database_system/l7py4lz/"}
{"body": "To be honest, I am an old computer engineer. My focus was on building home computers to sell, repair and upgrade. But that has no money in it then I moved to operations in few companies. And As any computer tech would tell you, we are required to do so much with so little and in the end we get dumped on when idiots break their computers. So, now I\u2019m thinking maybe get into servers hardware tech and go from there.", "author": "makzero", "created_utc": "2024-06-08 20:02:06", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7pxblu/"}
{"body": "Oh okay, I didn\u2019t know that was an option", "author": "makzero", "created_utc": "2024-06-08 19:59:34", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7pwxi0/"}
{"body": "Virtual private server", "author": "WiscoSippi", "created_utc": "2024-06-08 19:57:32", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7pwm6a/"}
{"body": "Virtual private server.  Just a VM in the cloud that you can do whatever you want with.  You won't be able to to physical hardware stuff, but it's way cheaper than buying a server &amp; paying the electric bill to run it.", "author": "jaredrileysmith", "created_utc": "2024-06-08 19:57:32", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7pwm5h/"}
{"body": "How did you manage that?", "author": "SuitCool", "created_utc": "2024-06-08 19:48:42", "permalink": "/r/dataengineering/comments/1daj3n0/what_do_you_predict_with_be_announced_at_the/l7pv8y5/"}
{"body": "You are right, that\u2019s a Great point.", "author": "makzero", "created_utc": "2024-06-08 19:42:01", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7pu7pw/"}
{"body": "\ud83d\ude2f I didn\u2019t know any of that existed. Thank you", "author": "makzero", "created_utc": "2024-06-08 19:41:13", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7pu3fg/"}
{"body": "What\u2019s a vps?", "author": "makzero", "created_utc": "2024-06-08 19:40:09", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7ptxlt/"}
{"body": "Oh okay. That\u2019s great information thank you", "author": "makzero", "created_utc": "2024-06-08 19:39:35", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7ptuho/"}
{"body": "Definitely overkill for just tinkering. And you will figure\u00a0that out as soon as you set eyes on it or buy it and plug it in.\u00a0\n\n\nI suggest you identify the types of tinkering or projects you'd like to work on and look into how to make that work with your existing hardware. For example, you can spin up Developer/Enterprise SQL Server instances on docker in just a few minutes. The same goes for many new platforms that are out there today. Python virtual environments or Conda are great too.\u00a0\n\n\nAll of my old PC gaming hardware gets a 2nd life as server hardware, including old graphics cards. Those are useful for\u00a0hardware acceleration to transcode videos, or loading quantized LLMs for example.", "author": "benchwrmr22", "created_utc": "2024-06-08 19:38:02", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7ptlw9/"}
{"body": "Will it work? Yes. But most likely it will be slower. Bigtable probably sorts by key, which makes lookups fast. This is not true for OS filesystem.", "author": "hadoopfromscratch", "created_utc": "2024-06-08 19:32:58", "permalink": "/r/dataengineering/comments/1db88q6/key_value_conundrum/l7pstyx/"}
{"body": "The most important factor to consider is the power usage. If you intend to use this server for file backups, it will need to run 24/7, which can significantly increase your expenses. If you choose not to run the server continuously, it could be a worthwhile investment. Objectively, it may not be the best purchase, but it depends on your specific needs and or goals. you can use tools online to estimate power consumption e.g. [https://www.rapidtables.com/calc/electric/energy-cost-calculator.html](https://www.rapidtables.com/calc/electric/energy-cost-calculator.html)", "author": "whiteboreded", "created_utc": "2024-06-08 19:29:06", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7ps8pk/"}
{"body": "NO!  The CPU architecture is 14 years old!\n\nFor a few hundred more, you can get a first gen Scalable Xeon that will run circles around these systems.  \n\nI'd also recommend getting a pedestal server instead of a rack mount.  Your ears will thank you.\n\nOr as others have pointed out, get a VPS and a backup service like Backblaze.  I think they offer 10GB of blob storage for free.", "author": "Visual_Cabinet_3718", "created_utc": "2024-06-08 19:25:42", "permalink": "/r/dataengineering/comments/1db7v1u/is_this_a_good_deal_listed_in_my_local_facebook/l7prq4s/"}
{"body": "We use a metadata table with seperate schema and permissions for adf parameters. \nWe store the run id in a table for debugging the previous runs and take the output from the metadata table via stored procedures.", "author": "EvenChilli2341", "created_utc": "2024-06-08 19:11:39", "permalink": "/r/dataengineering/comments/1db5ke6/how_to_efficiently_manage_parameters_in_adf/l7ppl16/"}
{"body": "Use the IMDB db, pop culture is relateble", "author": "Drunk_redditor650", "created_utc": "2024-06-08 19:08:44", "permalink": "/r/dataengineering/comments/1dal3z9/how_did_you_find_ideas_for_portfoliopersonal/l7pp5b2/"}
